{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greek-scratch",
   "metadata": {},
   "source": [
    "# Hugging Face를 이용한 모델 생성 및 평가 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-rochester",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 초록\n",
    "***\n",
    "<span style=\"font-size:11pt; line-height:1.8;\">\n",
    "    &nbsp; &nbsp; Hugging Face의 transformers를 이용하여 BERT, RoBERTa 모델과 토크나이저를 불러와 MNLI 데이터를 학습하고 각 모델의 성능을 확인하였다. 학습 데이터는 총 392,702개이며, 검증 데이터와 학습 데이터는 각 항목 별로 약 9,700개 이다. 검증 데이터와 학습 데이터는, 학습 데이터에 포함된 도메인 자료인 Matched 데이터와 포함 되지 않은 Mismatched 데이터로 구분 된다. 데이터 전처리는 '검증 및 테스트 데이터 분할',  '모델별 토크나이저를 이용한 학습 데이터 생성' 순으로 진행 하였다. BERT와 RoBERTa 모델을 생성하고 Adam을 이용하여 총 5회 학습 하였다. 학습한 모델을 테스트 데이터로 평가한 결과, BERT 모델의 Matched 테스트 데이터의 정확도는 0.435 이고 Mismatched 테스트 데이터의 정확도는 0.460 이다. RoBERTa 모델의 Matched 테스트 데이터의 정확도는 0.534 이고 Mismatched 테스트 데이터의 정확도는 0.537 이다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-military",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 서론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 본 예제는 NLP 프레임워크 중 하나인 Hugging Face의 transformers를 이용하여 Multi-Genre Natural Language Inference(MNLI) 문제를\n",
    "해결하고자 합니다. Hugging Face의 transformers의 경우 학습된 모델과 토크나이저를 사용할 수 있다는 이점이 있습니다. 또한 사전학습된 transformers의 BERT와 RoBERTa 모델과 토크나이저를 이용하여 두 모델의 성능을 비교하고자 합니다. 다음은 예제의 진행 과정을 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "> _1. 데이터 분석_\n",
    ">\n",
    "> _2. 데이터 전처리_\n",
    ">\n",
    "> _3. 모델 생성_\n",
    ">\n",
    "> _4. 모델 학습 및 평가_\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-cooler",
   "metadata": {},
   "source": [
    "#### _들어가기 앞서..._\n",
    "***\n",
    "+ `tensorflow_datasets`의 `glue/mnli` 데이터셋을 받기 위해 라이브러리 버전을 업그레이드 합니다.\n",
    "\n",
    "`$pip install tensorflow-datasets -U`\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-branch",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 데이터 분석\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; GLUE의 MNLI는 전제 문장(Premise)과 가설 문장(Hypothesis)이 주어졌을 때, 전제와 가설의 관계를 구분(class)하는 것을 목표로 합니다. 전제와 가설의 관계는 수반(entailment), 모순(contradiction), 중립(neutral)으로 총 세 개로 구분 됩니다. 데이터는 연설, 소설, 기관 보고서 등 10개 도메인의 자료를 사용 합니다. 데이터는 학습, 검증, 테스트 데이터가 있으며, 검증 및 테스트 데이터의 경우, 학습 데이터에 포함되지 않은(mismatched) 도메인의 자료에 해당하는 데이터와 학습 데이터에 포함된(matched) 도메인의 자료로 구분되어 있습니다. 학습 데이터는 총 392,702개이며, 검증 데이터와 학습 데이터는 각 항목 별로 약 9,700개 입니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-liberty",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 호출\n",
    "***\n",
    "+ 예제에서 사용할 라이브러리를 호출 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excess-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   #디렉토리 관리\n",
    "\n",
    "\n",
    "import tensorflow as tf   #신경망\n",
    "import tensorflow_datasets as tfds   #데이터셋\n",
    "from dataclasses import asdict   #데이터 클래스\n",
    "\n",
    "\n",
    "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures   #허깅 페이스\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification   #BERT\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification   #RoBerta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-chess",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### MNLI 데이터 불러오기\n",
    "***\n",
    "+ 텐서플로우 데이터셋을 이용하여 GLUE MNLI 데이터셋을 불러옵니다.\n",
    "\n",
    "\n",
    "+ 학습 데이터는 392,702개 입니다.\n",
    "\n",
    "\n",
    "+ 학습 데이터에 포함된(matched) 도메인의 검증 데이터는 9,815개, 테스트 데이터는 9,796개 입니다.\n",
    "\n",
    "\n",
    "+ 학습 데이터에 포함 되지 않은(mismatched) 도메인의 검증 데이터는 9,832개, 테스트 데이터는 9,847개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuing-geneva",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /aiffel/tensorflow_datasets/glue/mnli/2.0.0\n",
      "INFO:absl:Reusing dataset glue (/aiffel/tensorflow_datasets/glue/mnli/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset glue for split None, from /aiffel/tensorflow_datasets/glue/mnli/2.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "0: train(392,702)\n",
      "1: validation_matched(9,815)\n",
      "2: validation_mismatched(9,832)\n",
      "3: test_matched(9,796)\n",
      "4: test_mismatched(9,847)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('glue/mnli', with_info=True)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "for idx, (domain, data) in enumerate(dataset.items()):\n",
    "    print(f\"{idx}: {domain}({len(data):,})\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-small",
   "metadata": {},
   "source": [
    "#### 학습 데이터 출처\n",
    "***\n",
    "+ TensorFlow, GLUE MNLI(2019), https://www.tensorflow.org/datasets/catalog/glue\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-irrigation",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### MNLI 데이터 샘플 출력\n",
    "***\n",
    "+ MNLI 데이터 중 레코드 하나를 출력 합니다.\n",
    "\n",
    "\n",
    "+ MNLI 데이터는 전제 문장(Premise)와 가설 문장(Hypothesis) 그리고 두 문장의 관계에 대한 값(Label)로 이루어져 있습니다.\n",
    "\n",
    "\n",
    "+ Label은 모순(contradiction: 0), 수반(entailment: 1), 중립(neutral: 2)으로 총 세 개 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "typical-update",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Hypothesis: b'Meaningful partnerships with stakeholders is crucial.'\n",
      "\n",
      "Premise: b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.'\n",
      "\n",
      "Label: 1\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "for data in dataset['train']:\n",
    "    print(\"Hypothesis:\", data['hypothesis'].numpy(), end=\"\\n\\n\")\n",
    "    print(\"Premise:\", data['premise'].numpy(), end=\"\\n\\n\")\n",
    "    print(\"Label:\", data['label'].numpy())\n",
    "    break\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-calvin",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. 데이터 전처리\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 데이터 전처리는 '검증 및 테스트 데이터 분할', 'MNLI Processor 생성', '토크나이저를 이용한 학습 데이터 생성' 순으로 진행 됩니다. 검증 데이터의 경우, Matched 데이터와 Mismatched 데이터를 합하여 이를 학습 시, 검증에 사용 합니다. MNLI Processor를 이용하여 데이터를 모델에 입력하기 적합하도록 전처리 하고 BERT와 RoBERTa 토크나이저를 이용하여 각 모델에 입력하기 위한 데이터셋을 생성 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-kitty",
   "metadata": {},
   "source": [
    "#### 검증 및 테스트 데이터 섞기 및 분할\n",
    "***\n",
    "+ 검증(validation) 데이터와 테스트(test) 데이터를 섞어준 후, 다시 분할 하여 줍니다.\n",
    "\n",
    "\n",
    "+ 검증 데이터의 경우 matched 데이터와 mismatched 데이터를 결합하여 학습 시, 모델의 성능을 확인 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-asthma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "matched_val Num: 9,815\tmismatched_val Num: 9,832\n",
      "matched_test Num: 9,796\tmismatched_test Num: 9,847\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dataset, val_size):    \n",
    "    dataset = dataset.shuffle(len(dataset))\n",
    "    val_dataset = dataset.shuffle(len(dataset)).take(val_size)\n",
    "    test_dataset = dataset.shuffle(len(dataset)).skip(val_size)\n",
    "    return (val_dataset, test_dataset)\n",
    "\n",
    "\n",
    "matched_data = dataset['test_matched'].concatenate(dataset['validation_matched'])\n",
    "mismatched_data = dataset['test_mismatched'].concatenate(dataset['validation_mismatched'])\n",
    "\n",
    "matched_val, matched_test = split_dataset(matched_data, len(dataset['validation_matched']))\n",
    "mismatched_val, mismatched_test = split_dataset(mismatched_data, len(dataset['validation_mismatched']))\n",
    "\n",
    "val = mismatched_val.concatenate(matched_val)\n",
    "\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"matched_val Num: {len(matched_val):,}\\tmismatched_val Num: {len(mismatched_val):,}\")\n",
    "print(f\"matched_test Num: {len(matched_test):,}\\tmismatched_test Num: {len(mismatched_test):,}\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-initial",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### MNLI Processor 생성\n",
    "***\n",
    "+ dataset을 모델에 입력하기에 적합하도록 전처리 하는 역할의 MNLI Processor를 생성 합니다.\n",
    "\n",
    "\n",
    "+ 추상 클래스인 DataProcessor를 생성한 후, 이를 MNLI Processor에 상속 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "institutional-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추상 클래스=============================================\n",
    "class DataProcessor:\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"\n",
    "        Gets an example from a dict with tensorflow tensors.\n",
    "\n",
    "        Args:\n",
    "            tensor_dict: Keys and values should match the corresponding Glue\n",
    "                tensorflow_dataset examples.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the test set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def tfds_map(self, example):\n",
    "        \"\"\"\n",
    "        Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
    "        examples to the correct format.\n",
    "        \"\"\"\n",
    "        if len(self.get_labels()) > 1:\n",
    "            example.label = self.get_labels()[int(example.label)]\n",
    "        return example\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))\n",
    "#End=====================================================\n",
    "\n",
    "\n",
    "#MNLI Processor==========================================\n",
    "class MnliProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MRPC data set (GLUE version).\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev_matched.tsv\")), \"dev_matched\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test_matched.tsv\")), \"test_matched\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[3]\n",
    "            text_b = line[4]\n",
    "            label = None if set_type == \"test\" else line[0]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples\n",
    "#End====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-placement",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### MNLI Processor 예제 출력\n",
    "***\n",
    "+ 기존 dataset데이터를 MNLI Processor를 이용하여 전처리한 데이터를 출력 합니다.\n",
    "\n",
    "\n",
    "+ 기존 Dictionary 형태의 데이터가 transformers의 Processor 형태로 변환된 것을 확인할 수 있습니다.\n",
    "\n",
    "\n",
    "+ Label의 경우, 세 개의 클래스가 올바르게 적용된 것을 확인할 수 있습니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-cambodia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================Original Data============================================\n",
      "{'hypothesis': <tf.Tensor: shape=(), dtype=string, numpy=b'Meaningful partnerships with stakeholders is crucial.'>, 'idx': <tf.Tensor: shape=(), dtype=int32, numpy=16399>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'premise': <tf.Tensor: shape=(), dtype=string, numpy=b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.'>}\n",
      "\n",
      "<class 'dict'>\n",
      "====================================================================================================\n",
      "\n",
      "===========================================Processed Data===========================================\n",
      "InputExample(guid=16399, text_a='In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', text_b='Meaningful partnerships with stakeholders is crucial.', label='1')\n",
      "\n",
      "<class 'transformers.data.processors.utils.InputExample'>\n",
      "====================================================================================================\n",
      "\n",
      "Label {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "processor = MnliProcessor()\n",
    "examples = dataset['train'].take(1)\n",
    "\n",
    "for example in examples:\n",
    "    print(\"Original Data\".center(100, \"=\"))\n",
    "    print(example, end=\"\\n\\n\")\n",
    "    print(type(example))\n",
    "    print(\"=\" * 100, end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Processed Data\".center(100, \"=\"))\n",
    "    example = processor.get_example_from_tensor_dict(example)\n",
    "    print(example, end=\"\\n\\n\")\n",
    "    print(type(example))\n",
    "    print(\"=\" * 100, end=\"\\n\\n\")\n",
    "    \n",
    "    label_map = {label: i for i, label in enumerate(processor.get_labels())}\n",
    "    print(\"Label\", label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-denial",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문장 정수 인코딩 및 데이터셋 생성 함수 정의\n",
    "***\n",
    "+ 토크나이저를 이용하여 데이터를 정수화 하는 함수와 정수화한 데이터를 Tensorflow 데이터셋으로 생성하는 함수를 정의 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facial-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정수 인코딩==========================================\n",
    "def _glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"claasification\") :\n",
    "    if max_length is None :\n",
    "        max_length = tokenizer.max_len\n",
    "    if label_list is None:\n",
    "        label_list = processor.get_labels()\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    labels = [label_map[example.label] for example in examples]\n",
    "\n",
    "    batch_encoding = tokenizer(\n",
    "        [(example.text_a, example.text_b) for example in examples],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(examples)):\n",
    "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "\n",
    "        feature = InputFeatures(**inputs, label=labels[i])\n",
    "        features.append(feature)\n",
    "\n",
    "    return features\n",
    "#End==================================================\n",
    "\n",
    "\n",
    "#tf_dataset===========================================\n",
    "def tf_glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"classification\") :\n",
    "    \"\"\"\n",
    "    :param examples: tf.data.Dataset\n",
    "    :param tokenizer: pretrained tokenizer\n",
    "    :param max_length: example의 최대 길이(기본값 : tokenizer의 max_len)\n",
    "    :param task: GLUE task 이름\n",
    "    :param label_list: 라벨 리스트\n",
    "    :param output_mode: \"regression\" or \"classification\"\n",
    "\n",
    "    :return: task에 맞도록 feature가 구성된 tf.data.Dataset\n",
    "    \"\"\"\n",
    "    examples = [processor.tfds_map(processor.get_example_from_tensor_dict(example)) for example in examples]\n",
    "    features = _glue_convert_examples_to_features(examples, tokenizer, max_length, processor)\n",
    "    label_type = tf.int64\n",
    "\n",
    "    def gen():\n",
    "        for ex in features:\n",
    "            d = {k: v for k, v in asdict(ex).items() if v is not None}\n",
    "            label = d.pop(\"label\")\n",
    "            yield (d, label)\n",
    "\n",
    "    input_names = [\"input_ids\"] + tokenizer.model_input_names\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({k: tf.int32 for k in input_names}, label_type),\n",
    "        ({k: tf.TensorShape([None]) for k in input_names}, tf.TensorShape([])),\n",
    "    )\n",
    "#End=================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-folder",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 토크나이저 불러오기\n",
    "***\n",
    "+ BERT와 RoBERTa의 MNLI에 대한 성능을 확인 하기 위해, Transformers로부터 BERT와 RoBERTa의 토크나이저를 불러옵니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "champion-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-steam",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 학습 데이터셋 생성\n",
    "***\n",
    "+ 앞서 정의한 전처리 함수와 토크나이저를 이용하여 BERT와 RoBerta를 학습하기 위한 데이터셋을 생성 합니다.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "native-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_batch(raw_dataset_list, tokenizer, processor):\n",
    "    dataset_list = []\n",
    "    for idx, dataset in enumerate(raw_dataset_list):\n",
    "        data = tf_glue_convert_examples_to_features(dataset, tokenizer, max_length=128, processor=processor)\n",
    "        \n",
    "        if idx == 0:\n",
    "            data_batch = data.shuffle(100).batch(16).repeat(2)\n",
    "        else:\n",
    "            data_batch = data.shuffle(100).batch(16)\n",
    "        dataset_list.append(data_batch)\n",
    "    return dataset_list\n",
    "    \n",
    "    \n",
    "raw_dataset_list = (dataset['train'], val, matched_test, mismatched_test)\n",
    "\n",
    "bert_train, bert_val, bert_m_test, bert_mism_test = get_dataset_batch(\n",
    "    raw_dataset_list, bert_tokenizer, processor\n",
    ")\n",
    "\n",
    "robert_train, robert_val, robert_m_test, robert_mism_test = get_dataset_batch(\n",
    "    raw_dataset_list, roberta_tokenizer, processor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-spoke",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. 모델 생성 및 학습\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; BERT와 RoBERTa 모델을 생성하고 MNLI 데이터셋을 학습 합니다. RoBERTa는 Robustly Optimized BERT Pretraining Approach로 BERT의 pre-training 단계의 하이퍼 파라미터를 다양하게 변경하여 최적화한 모델에 해당 합니다. RoBERTa의 특징은 pre-train 시에 160GB의 학습 데이터를 이용하였으며, GLUE, SQuAD, RACE 문제를 중심으로 학습 하였습니다. 또한, 배치 사이즈가 클수록 성능이 좋아져, 기존 BERT의 3배 크기의 배치 사이즈로 학습 하였습니다. 학습 옵티마이저는 Adam을 이용하고 학습 회수는 5회로 설정 합니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-bernard",
   "metadata": {},
   "source": [
    "#### 옵티마이저 설정\n",
    "***\n",
    "+ 옵티마이저의 경우 BERT와 RoBERTa에 동일하게 적용되기 때문에 미리 정의하여 줍니다.\n",
    "\n",
    "\n",
    "+ 옵티마이저는 Adam을 이용합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "drawn-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-latter",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.1. BERT\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; BERT 모델을 생성하고 MNLI 데이터셋을 학습 합니다. 모델의 파라미터 크기는 109,484,547 입니다. 총 5회 학습한 결과, 최종 검증 손실값은 1.080이고 정확도는 0.514 입니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-reputation",
   "metadata": {},
   "source": [
    "#### BERT 모델 생성\n",
    "***\n",
    "+ 모델을 생성하고 앞서 정의한 옵티마이저를 적용합니다.\n",
    "\n",
    "\n",
    "+ 모델의 파라미터 크기는 109,484,547 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "practical-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  2307      \n",
      "=================================================================\n",
      "Total params: 109,484,547\n",
      "Trainable params: 109,484,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "bert_model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-gregory",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### BERT 모델 학습\n",
    "***\n",
    "+ 앞서 생성한 데이터셋을 바탕으로 BERT 모델을 학습 합니다.\n",
    "\n",
    "\n",
    "+ 학습 회수는 총 5회로 설정 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satellite-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7df7cc08a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7df7cc08a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f7df7cc08a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - ETA: 0s - loss: 1.0892 - acc: 0.3814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 442s 4s/step - loss: 1.0888 - acc: 0.3821 - val_loss: 1.1026 - val_acc: 0.4277\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 422s 4s/step - loss: 0.8935 - acc: 0.5872 - val_loss: 1.0863 - val_acc: 0.4778\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 422s 4s/step - loss: 0.8019 - acc: 0.6598 - val_loss: 1.0590 - val_acc: 0.4817\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 422s 4s/step - loss: 0.7459 - acc: 0.6850 - val_loss: 1.1507 - val_acc: 0.5029\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 422s 4s/step - loss: 0.7582 - acc: 0.6634 - val_loss: 1.0802 - val_acc: 0.5144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7bec26b950>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.fit(bert_train, epochs=5, steps_per_epoch=115, validation_data=bert_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-virginia",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.2. RoBERTa\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; RoBERTa 모델을 생성하고 MNLI 데이터셋을 학습 합니다. 모델의 파라미터 크기는 124,647,939 입니다. 총 5회 학습한 결과, 최종 검증 손실값은 1.358이고 정확도는 0.536 입니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-clinic",
   "metadata": {},
   "source": [
    "#### RoBERTa 모델 생성\n",
    "***\n",
    "+ 모델을 생성하고 앞서 정의한 옵티마이저를 적용합니다.\n",
    "\n",
    "\n",
    "+ 모델의 파라미터 크기는 124,647,939 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "genuine-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  124055040 \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  592899    \n",
      "=================================================================\n",
      "Total params: 124,647,939\n",
      "Trainable params: 124,647,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "roberta_model = TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\n",
    "roberta_model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "roberta_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-stewart",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### RoBERTa 모델 학습\n",
    "***\n",
    "+ 앞서 생성한 데이터셋을 바탕으로 RoBERTa 모델을 학습 합니다.\n",
    "\n",
    "\n",
    "+ 학습 회수는 총 5회로 설정 합니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "actual-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f915e1918a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f915e1918a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f915e1918a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - ETA: 0s - loss: 1.0922 - acc: 0.3681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 438s 4s/step - loss: 1.0922 - acc: 0.3682 - val_loss: 1.1054 - val_acc: 0.1580\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 421s 4s/step - loss: 1.1014 - acc: 0.3455 - val_loss: 1.0801 - val_acc: 0.3372\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 419s 4s/step - loss: 0.9660 - acc: 0.5556 - val_loss: 1.0942 - val_acc: 0.4741\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 419s 4s/step - loss: 0.7794 - acc: 0.6777 - val_loss: 1.0392 - val_acc: 0.5808\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 419s 4s/step - loss: 0.7092 - acc: 0.7068 - val_loss: 1.3580 - val_acc: 0.5357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ef9495250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.fit(robert_train, epochs=5, steps_per_epoch=115, validation_data=robert_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-award",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5. 모델 평가\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 학습된 각 모델을 테스트 데이터를 이용하여 평가 합니다. 테스트 데이터의 경우 학습 데이터에 포함되지 않은 도메인 자료인 Mismatched 데이터 9,847개와 포함된 도메인 자료 데이터인 Matched 데이터 9,796개로 이루어져 있습니다. 학습 데이터에 포함되지 않은 자료를 바탕으로 모델을 학습하는 것은 모델이 학습하지 않은 도메인에 대한 평가가 이루어지기 때문에 모델의 일반화 능력을 확인할 수 있습니다.\n",
    "</span><br><br>\n",
    "\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; 테스트 데이터에 대한 BERT 모델 성능을 확인한 결과 Matched 테스트 데이터의 손실값은 1.032, 정확도는 0.435이고, Mismatched 테스트 데이터의의 손실값은 1.011, 정확도는 0.460 입니다. 테스트 데이터에 대한 RoBERTa 모델 성능을 확인한 결과 Matched 테스트 데이터의 손실값은 1.352, 정확도는 0.534이고, Mismatched 테스트 데이터의의 손실값은 1.355, 정확도는 0.537 입니다.\n",
    "</span>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-expansion",
   "metadata": {},
   "source": [
    "#### 테스트 데이터에 대한 BERT 모델 성능 확인\n",
    "***\n",
    "+ 학습 데이터에 포함된 도메인의 테스트 데이터(Matched)와 포함되지 않은 테스트 데이터(MisMatched)를 이용하여 모델의 성능을 확인 합니다.\n",
    "\n",
    "\n",
    "+ Matched 테스트 데이터의 손실값은 1.032이며, Mismatched 테스트 데이터의 손실값은 1.011 입니다.\n",
    "\n",
    "\n",
    "+ Matched 테스트 데이터의 정확도은 0.435이며, Mismatched 테스트 데이터의 정확도은 0.460 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sonic-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 165s 270ms/step - loss: 1.0318 - acc: 0.4346\n",
      "616/616 [==============================] - 167s 271ms/step - loss: 1.0106 - acc: 0.4600\n",
      "\n",
      "Matched Test data\tLoss: 1.032\tAccuracy: 0.435\n",
      "Mismatched Test data\tLoss: 1.011\tAccuracy: 0.460\n"
     ]
    }
   ],
   "source": [
    "matched_result = bert_model.evaluate(bert_m_test)\n",
    "mismatched_result = bert_model.evaluate(bert_mism_test)\n",
    "\n",
    "print(f\"\\nMatched Test data\\tLoss: {matched_result[0]:.3f}\\tAccuracy: {matched_result[1]:.3f}\")\n",
    "print(f\"Mismatched Test data\\tLoss: {mismatched_result[0]:.3f}\\tAccuracy: {mismatched_result[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-therapist",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 테스트 데이터에 대한 RoBERTa 모델 성능 확인\n",
    "***\n",
    "+ 학습 데이터에 포함된 도메인의 테스트 데이터(Matched)와 포함되지 않은 테스트 데이터(MisMatched)를 이용하여 모델의 성능을 확인 합니다.\n",
    "\n",
    "\n",
    "+ Matched 테스트 데이터의 손실값은 1.352이며, Mismatched 테스트 데이터의 손실값은 1.355 입니다.\n",
    "\n",
    "\n",
    "+ Matched 테스트 데이터의 정확도는 0.534이며, Mismatched 테스트 데이터의 정확도는 0.537 입니다.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defensive-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 165s 268ms/step - loss: 1.3524 - acc: 0.5342\n",
      "616/616 [==============================] - 166s 269ms/step - loss: 1.3546 - acc: 0.5366\n",
      "\n",
      "Matched Test data\tLoss: 1.352\tAccuracy: 0.534\n",
      "Mismatched Test data\tLoss: 1.355\tAccuracy: 0.537\n"
     ]
    }
   ],
   "source": [
    "matched_result = roberta_model.evaluate(robert_m_test)\n",
    "mismatched_result = roberta_model.evaluate(robert_mism_test)\n",
    "\n",
    "print(f\"\\nMatched Test data\\tLoss: {matched_result[0]:.3f}\\tAccuracy: {matched_result[1]:.3f}\")\n",
    "print(f\"Mismatched Test data\\tLoss: {mismatched_result[0]:.3f}\\tAccuracy: {mismatched_result[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-grounds",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 6. 결론\n",
    "***\n",
    "<span style=\"font-size:12pt; line-height:1.7; font-family:Serif;\">\n",
    "    &nbsp; &nbsp; Hugging Face의 transformers를 이용하여 BERT, RoBERTa 모델과 토크나이저를 불러와 MNLI 데이터를 학습하고 각 모델의 성능을 확인하였습니다. Hugging Face는 NLP 프레임워크로, pre-trained 모델과 토크나이저를 쉽게 사용할 수 있습니다. MNLI 데이터를 transformers Processor를 이용하여 전처리 한 후, 각 모델을 학습하였습니다. 두 모델 모두 Adam 옵티마이저를 사용하였으며, 총 5회 학습 하였습니다. 학습된 모델을 테스트 데이터로 평가한 결과, BERT 모델의 Matched 테스트 데이터의 정확도는 0.435 이고 Mismatched 테스트 데이터의 정확도는 0.460 입니다. RoBERTa 모델의 Matched 테스트 데이터의 정확도는 0.534 이고 Mismatched 테스트 데이터의 정확도는 0.537 입니다. 따라서 RoBERTa가 BERT 보다 성능이 우세하다 고 할 수 있습니다. [표 1]은 BERT와 RoBERTa 모델의 성능 지표를 제시한 것입니다.\n",
    "</span><br><br>\n",
    "\n",
    "\n",
    "|Model|Validation Loss|Validation Accuracy|Matched Test Loss|Matched Test Accuracy|Mismatched Test Loss|Mismatched Test Accuracy|\n",
    "|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|\n",
    "|**BERT**|1.080|0.514|1.032|0.435|1.011|0.460|\n",
    "|**RoBERTa**|1.358|**0.536**|1.352|**0.534**|1.355|**0.537**|\n",
    "\n",
    "[표 1] BERT, RoBERTa 모델의 성능 지표\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-charge",
   "metadata": {},
   "source": [
    "#### 형상관리 기록\n",
    "***\n",
    "+ v1_1: 실습 예제 진행\n",
    "\n",
    "\n",
    "+ v1_2: 제출 예제 진행\n",
    "\n",
    "\n",
    "+ v2_1: BERT 모델 사용\n",
    "\n",
    "\n",
    "+ v3_1: RoBerta 모델 사용\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
